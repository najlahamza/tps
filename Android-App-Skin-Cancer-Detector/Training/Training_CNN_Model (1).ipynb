{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfURusoXDTfr"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl2TbNC_8VRZ",
        "outputId": "45952b49-2f03-413f-ce88-fc59f7f59070"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMcYyxx0DVSo"
      },
      "source": [
        "train_dir='/content/drive/MyDrive/Android-App-Skin-Cancer-Detector/Android-App-Skin-Cancer-Detector/Training/Dataset'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktn0SkgXDXP8"
      },
      "source": [
        "Labels = ['Benign', 'Malignant']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubSv3rnyDZBE",
        "outputId": "f96d6bb8-cbc9-4b9f-caf5-d3a0ce5ac09c"
      },
      "source": [
        "print (\"class : \") \n",
        "for i in range(len(Labels)): \n",
        "    print (i, end = \" \") \n",
        "    print (Labels[i]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class : \n",
            "0 Benign\n",
            "1 Malignant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkVtS4TkDarf",
        "outputId": "1374a86a-38ac-46c0-b86d-e88de2573d6f"
      },
      "source": [
        "print('Number of classes:',len(Labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXdEgAj5DcBL"
      },
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) \n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "BATCH_SIZE = 16 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYNXTeVj-K_w",
        "outputId": "f3240bae-1fde-42c3-e07e-5a449a49e30a"
      },
      "source": [
        "IMAGE_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAGIZTBfDdcJ",
        "outputId": "fd66e023-db65-467f-f5b3-5bbc14429ac4"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, \n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2, \n",
        "      zoom_range=0.2,\n",
        "      fill_mode='nearest',\n",
        "      validation_split=0.4)\n",
        "  \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    subset=\"training\", \n",
        "    shuffle=True, \n",
        "    seed=42,\n",
        "    color_mode=\"rgb\", \n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    shuffle=False, \n",
        "    seed=42,\n",
        "    color_mode=\"rgb\", \n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\",\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEUMzRB3De5z"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,input_shape=IMAGE_SIZE+(3,), output_shape=[FV_SIZE]  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Sc06P1DgUu"
      },
      "source": [
        "do_fine_tuning = False \n",
        "if do_fine_tuning:\n",
        "  feature_extractor.trainable = True\n",
        "  for layer in base_model.layers[-30:]:\n",
        "    layer.trainable =True\n",
        "  \n",
        "else:\n",
        "  feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHw7IFhLDhzn",
        "outputId": "b92c30d3-746c-48ab-bf8a-49d2903fd528"
      },
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    feature_extractor,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "#model.build((None,)+IMAGE_SIZE+(3,))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model with https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              5919312   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               655872    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,578,258\n",
            "Trainable params: 657,922\n",
            "Non-trainable params: 5,920,336\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqW5HaZ0DjWK"
      },
      "source": [
        "LEARNING_RATE = 0.0005 \n",
        "model.compile(\n",
        "   optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), \n",
        "   loss='categorical_crossentropy',\n",
        "   metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6F66X8xDmMD",
        "outputId": "3780c327-02c4-4ede-a5c7-fd0bd9205c8a"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping_monitor = EarlyStopping(monitor = 'loss', patience = 3)\n",
        "EPOCHS=50\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
        "        callbacks= [early_stopping_monitor])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.8284 - accuracy: 0.5000 - val_loss: 0.6324 - val_accuracy: 0.6875\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 1s 640ms/step - loss: 0.7662 - accuracy: 0.3750 - val_loss: 0.6308 - val_accuracy: 0.5625\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 0.7887 - accuracy: 0.6250 - val_loss: 0.6126 - val_accuracy: 0.6875\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 1s 573ms/step - loss: 0.3061 - accuracy: 0.8750 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 1s 615ms/step - loss: 0.3229 - accuracy: 0.8750 - val_loss: 0.5682 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 1s 625ms/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 1s 618ms/step - loss: 0.1997 - accuracy: 0.9375 - val_loss: 0.4710 - val_accuracy: 0.8125\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.3174 - accuracy: 0.8750 - val_loss: 0.4468 - val_accuracy: 0.8125\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 1s 633ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.8750\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8750\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.8750\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "4oWHMV0_Dn4K",
        "outputId": "dbf6fc9b-0edf-4a10-8f21-a24a8d6d9711"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-938400c1d891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m   2763\u001b[0m         is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (12,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xd1vA4qDpj7"
      },
      "source": [
        "import random\n",
        "import cv2\n",
        "def upload(filename):\n",
        "    img = cv2.imread(os.path.join(train_dir, filename))\n",
        "    img = cv2.resize(img, (224, 224) )\n",
        "    img = img /255\n",
        "    \n",
        "    return img\n",
        "\n",
        "def pre_result(image):\n",
        "    x = model.predict(np.asarray([img]))[0]\n",
        "    classx = np.argmax(x)\n",
        "    \n",
        "    return {Labels[classx]: x[classx]}\n",
        "\n",
        "images = random.sample(validation_generator.filenames, 16)\n",
        "\n",
        "for idx, filename in enumerate(images):\n",
        "    \n",
        "    \n",
        "    img = upload(filename)\n",
        "    prediction = pre_result(img)\n",
        "    print(\"class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n",
        "    plt.imshow(img)\n",
        "    plt.figure(idx)    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqM6Df0cDrE8"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "predictions1 = model.predict(validation_generator, steps=len(validation_generator))\n",
        "y = np.argmax(predictions1, axis=1)\n",
        "\n",
        "print('Classification Report')\n",
        "cr = classification_report(y_true=validation_generator.classes, y_pred=y, target_names=validation_generator.class_indices)\n",
        "print(cr)\n",
        "\n",
        "evaluates = model.evaluate(validation_generator)\n",
        "\n",
        "print(evaluates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq1fUcu1DssZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(validation_generator.classes, y)\n",
        "df = pd.DataFrame(cm, columns=validation_generator.class_indices)\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.heatmap(df, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9no8-aoGQZo"
      },
      "source": [
        "cd /content/drive/MyDrive/Buffml/code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUB9-0jnH9MP"
      },
      "source": [
        "#Export as saved model and convert to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EQmFGdZGX1H"
      },
      "source": [
        "import time\n",
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "tf.keras.models.save_model(model, export_path)\n",
        "\n",
        "export_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOpETStsGr4-"
      },
      "source": [
        "# Now confirm that we can reload it, and it still gives the same results\n",
        "reloaded = tf.keras.models.load_model(export_path, custom_objects={'KerasLayer':hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYBuzvmCH8Ys"
      },
      "source": [
        "def predict_reload(image):\n",
        "    probabilities = reloaded.predict(np.asarray([img]))[0]\n",
        "    class_idx = np.argmax(probabilities)\n",
        "    \n",
        "    return {Labels[class_idx]: probabilities[class_idx]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH730cT7INym"
      },
      "source": [
        "for idx, filename in enumerate(random.sample(validation_generator.filenames, 2)):\n",
        "    print(\"SOURCE: class: %s, file: %s\" % (os.path.split(filename)[0], filename))\n",
        "    \n",
        "    img = upload(filename)\n",
        "    prediction = predict_reload(img)\n",
        "    print(\"PREDICTED: class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n",
        "    plt.imshow(img)\n",
        "    plt.figure(idx)    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp7xvcCsIPlV"
      },
      "source": [
        "# convert the model to TFLite\n",
        "!mkdir \"tflite_models\"\n",
        "TFLITE_MODEL = \"tflite_models/model.tflite\"\n",
        "\n",
        "\n",
        "# Get the concrete function from the Keras model.\n",
        "run_model = tf.function(lambda x : reloaded(x))\n",
        "\n",
        "# Save the concrete function.\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")\n",
        "\n",
        "# Convert the model to standard TensorFlow Lite model\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converted_tflite_model = converter.convert()\n",
        "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTEBp7TpJACU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}